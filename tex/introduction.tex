\chapter{Introduction\label{chap:intro}}

% What are optimization problems and where do they occur
% Start by telling a story (running example throughout intro)
When somebody is looking for a new flat to buy or rent, most people will be comparing prices with the aim to find the cheapest flat possible that fulfils their requirements.
This is an example of what in mathematics is called an optimization problem.
Optimization problems can be summarized as the task of finding a ``best'' solution out of a collection of possible solutions available.
The notion of ``best'' that is used there is commonly that a ``cost'' associated with each solution shall be minimal.
Speaking in the example from above, the task is to find the flat from all flats that fulfils the requirements with the minimum cost or rent.
If the collection of possible solutions is discrete, we speak of \emph{combinatorial} optimization.

% Applications of optimization in literature
Combinatorial optimization problems do naturally arise in many areas, ranging from industrial applications over research to everyday tasks.
Examples in literature include scheduling of processes in an operating system~\autocite{}, supply chain optimization~\autocite{}, minimizing the loss of a neural network~\autocite{}, air traffic management~\autocite{}, clustering~\autocite{}, learning optimal classifiers~\autocite{} and many more.
Since there is such a variety of applications for combinatorial optimization, there is a plethora of work on solving these optimization problems~\autocite{}.

% Reveal conflicting second objective
Taking a closer look at the flat search example from the beginning, we can notice a problem emerging:
what does ``fulfilling'' the requirements mean?
Some requirements, like the number of rooms, might be easy to specify, but consider the distance of ones daily commute.
Rather than setting a fixed threshold as ``maximum $x$ kilometres distance'', what we might actually want to do is minimize this distance at the same time as the cost of the flat.
Now suddenly there are multiple objectives to take into account regarding what constitutes a ``best'' solution.
This problem is called \emph{multi-objective} optimization.

% Conflicting objectives and why there might be no single optimal solution
The crucial difference between single-objective and the multi-objective optimization is that there is no single notion of optimality for the multi-objective setting.
Whereas for a single objective function, there is a clear minimum (or maximum) and objective values can be clearly compared, this becomes less defined for the multi-objective case:
consider a flat with a cost of 100\,000 \texteuro{} and 4-kilometre daily commute and compare it to another flat that costs 80\,000 \texteuro{} and has a 3-kilometre commute.
In this case it is easy to say that the second option is more optimal.
Now compare the second option to another flat that costs 100\,000 \texteuro{} but only has a 1-kilometre commute.
We cannot easily say which one of these options is better, and the choice would depend on ones personal preference over the two objectives.
This situation commonly occurs when two of the objectives considered are in conflict, as the price of a flat and its commute might be if the commute is towards the city centre and flats in the city centre are more expensive.

% Pareto optimality
% Point out different nomenclature
In the context of our work, the notion of optimality for multi-objective optimization is that of pareto-optimality (also called efficiency in other contexts)~\autocite{Ehrgott2005-2}.
Intuitively, pareto optimality considers a solution optimal if there exists no other solution with better objective value for one objective and not worse for all the others. 
This definition would consider the two last flats from earlier both equally optimal.
Under pareto optimality the task of solving a multi-objective optimization problem can mean multiple things:
finding a single pareto-optimal solution, finding a representative solution for each pareto point (also called non-dominated point in literature~\autocite{Ehrgott2005-2}), or finding all pareto-optimal solutions.
The first of the tasks can be considered the least informative since there can be very different pareto-optimal solutions to the same problem.
Most approaches to solving multi-objective optimization under pareto optimality seem to focus on the second approach where a single solution per pareto point (i.e., tuple of pareto-optimal objective values) is computed.
This gives a human decision makes the ability to look at the results and choose the pareto-optimal solution that gives the best trade-off between the objectives after the fact instead of having to choose such a trade-off in advance.
The last task goes one step further and enumerates the full pareto front (i.e., all pareto-optimal solutions), even if multiple of the solutions might lead to the same objective values.
In this work we focus on the latter two tasks.

\TODO{Do I mention other notions of optimality here?}

% Bi-objective vs multi-objective
% Why bi-objective is interesting/enough
The handle on multiple objectives and what the objective values of an optimal solution actually mean can quickly become hard to grasp.
As humans, we can only really visualize three dimensions meaning a pareto front over four objectives is already an entirely abstract object while even a three-dimensional one is hard to visualize.
Imagine, for example, adding the objectives living space and renovations that need to be done into the flat search example.
With those four objectives, a lot more flats are going to be pareto-optimal, therefore not helping in the decision process.
Two objectives, however, form a good trade-off between gaining meaningful information from the second objective over just using a single one, being able to intuitively visualize the pareto front and not resulting in too many pareto-optimal solutions.
Additionally, objectives that are considered ``less important'' but should still somehow be included in the optimization can still be added as a threshold condition;
e.g., requiring that the living space is more than 60 $\text{m}^2$ rather than treating it as a separate objective.
For this reason, in this work we focus on \emph{bi-objective} optimization, developing an algorithm for finding either a single representative per pareto point or all pareto-optimal solutions.

% Applications of bi-objective optimization in iterature
Bi-objective optimization also appears naturally in many fields of application.
In machine learning, a regularization term---expressing how complex a certain model is---is often combined with the loss based on the classification error~\autocite{}.
Typically, this is done by forming a linear combination of the two components, but there is also research in treating the two objectives separately~\autocite{}.
A very similar idea can be used for learning interpretable machine learning models.
As a proxy for the objective of interpretability, typically a notion of ``size'' of the model is used, leading to a natural bi-objective optimization problem with the objectives classification error and model size~\autocite{}.
A bi-objective optimization problem also arises when wanting to create a portfolio of different solvers that together solve a set of benchmarks as fast as possible while also containing as few solvers as possible~\autocite{}.
There are also bi-objective optimization problems in network routing with the objectives load balancing and latency~\autocite{}.
In supply chain optimization, in addition to cost optimization, environmental aspects can be taken into consideration as a second objective~\autocite{}.

% Hardness of optimization problems
In the same way that there are different complexity classes for decision problems, these complexity classes can be extended to optimization problems as well.
Consider the $\mathcal{NP}$-complete set covering decision problem~\autocite{DBLP:conf/coco/Karp72} where for a collection $\sets$ of sets, the task is to determine whether a cover $\cover$ with cardinality smaller than a threshold $k$ exists so that the cover intersects all sets, i.e., $S \cap \cover \neq \emptyset$ for all $S\in\sets$.
The corresponding optimization problem, where the task is to find the \emph{smallest} such cover is $\mathcal{NP}$-hard.
Several well known $\mathcal{NP}$-commplete decision problems have corresponding $\mathcal{NP}$-hard optimization problems~\autocite{KorteVygen2018-15}.

\TODO{\lipsum[7-7]}

% Transition to approaches to solving optimization problems
\TODO{\lipsum[7-7]}

% Solving pipeline for declarative approaches
\TODO{\lipsum[8-8]}

% MaxSAT (and SAT)
\TODO{\lipsum[9-9]}

% SAT-based bi-/multi-objective optimization not very active in last years
% Motivation for researching that direction
\TODO{\lipsum[10-10]}

% Contributions
% Algorithm: single SAT solver; builds on MaxSAT; single vs all
% Evaluation: study efficiency of different MaxSAT algorithms
\TODO{define \algname{}}
\TODO{\lipsum[11-11]}

% Signposting for chapters
\TODO{\lipsum[12-12]}